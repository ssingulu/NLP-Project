{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYVRK7oaLNh2",
        "outputId": "1f1dc0ad-7f3a-4e76-f65f-b070712a8ebe"
      },
      "source": [
        "!python3 /content/mcq_training_lightning_1.py --model_name_or_path bert-base-uncased --hidden_dropout_prob 0.15 --max_input_seq_length 128 --output_dir ./  --predictions_file predictions.csv --TRAIN_FILE /content/data_hard.csv  --DEV_FILE /content/devnewdata_2.csv --train_batch_size 8 --eval_batch_size 8 --max_train_samples -1 --num_train_epochs 5 --gradient_accumulation_steps 1 --seed 42 --save_top_k -1 --learning_rate 5e-05 --write_dev_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training arguments Namespace(adam_epsilon=1e-08, distributed_backend=None, early_stop_callback=False, fp_16=False, max_grad_norm=1.0, n_gpu=-1, num_workers=8, opt_level='O1', warmup_steps=0, weight_decay=0.0)\n",
            "--------------------\n",
            "Model arguments Namespace(hidden_dropout_prob=0.15, max_input_seq_length=128, model_name_or_path='bert-base-uncased')\n",
            "--------------------\n",
            "Other arguments Namespace(DEV_FILE='/content/devnewdata_2.csv', TRAIN_FILE='/content/data_hard.csv', do_fast_dev_run=False, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, limit_train_batches=-1, limit_val_batches=-1, max_train_samples=-1, num_train_epochs=5, output_dir='./', predictions_file='predictions.csv', save_last=False, save_top_k=-1, seed=42, train_batch_size=8, write_dev_predictions=True)\n",
            "--------------------\n",
            "Global seed set to 42\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 23.7kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 431kB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 320kB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 643kB/s]\n",
            "Downloading: 100% 420M/420M [00:10<00:00, 40.3MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                  | Params\n",
            "------------------------------------------------\n",
            "0 | model | BertForMultipleChoice | 109 M \n",
            "------------------------------------------------\n",
            "109 M     Trainable params\n",
            "0         Non-trainable params\n",
            "109 M     Total params\n",
            "437.932   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:623: UserWarning: Checkpoint directory /content exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "Validation sanity check: 0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Validation sanity check:   0% 0/2 [00:00<?, ?it/s]--------------------\n",
            "Validation avg_loss:  tensor(1.1031, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2500, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_0_predictions.csv\n",
            "--------------------\n",
            "Global seed set to 42\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:408: UserWarning: The number of training samples (37) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n",
            "Epoch 0:  14% 40/282 [00:38<03:51,  1.04it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  21% 60/282 [00:46<02:50,  1.30it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  28% 80/282 [00:53<02:14,  1.50it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  35% 100/282 [01:00<01:50,  1.65it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  43% 120/282 [01:08<01:31,  1.76it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  50% 140/282 [01:15<01:16,  1.86it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  57% 160/282 [01:22<01:02,  1.94it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  64% 180/282 [01:29<00:50,  2.00it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  71% 200/282 [01:37<00:39,  2.06it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  78% 220/282 [01:44<00:29,  2.10it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  85% 240/282 [01:51<00:19,  2.15it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  92% 260/282 [01:59<00:10,  2.18it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Epoch 0:  99% 280/282 [02:06<00:00,  2.22it/s, loss=1.1, v_num=0, train_loss_step=1.020, train_acc_step=0.625]\n",
            "Validating: 100% 245/245 [01:29<00:00,  2.75it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.0999, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2939, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_0_predictions.csv\n",
            "--------------------\n",
            "Epoch 0: 100% 282/282 [02:08<00:00,  2.20it/s, loss=1.11, v_num=0, train_loss_step=1.100, train_acc_step=0.375]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(1.1058, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.3243, device='cuda:0')\n",
            "--------------------\n",
            "tcmalloc: large alloc 1092804608 bytes == 0x558b9dcb6000 @  0x7f4476917615 0x558ac666a4cc 0x558ac674a47a 0x558ac6670f0c 0x7f4471b699e4 0x7f4471b71b14 0x7f4471b46a60 0x7f43c9324f55 0x7f43c932088e 0x7f43c9328235 0x7f4471b46fae 0x7f44712bdaa8 0x558ac666e098 0x558ac66e14d9 0x558ac66dbced 0x558ac666ebda 0x558ac66dc915 0x558ac66db9ee 0x558ac666ebda 0x558ac66e0d00 0x558ac666eafa 0x558ac66dc915 0x558ac66db9ee 0x558ac666ebda 0x558ac66dcc0d 0x558ac666eafa 0x558ac66dcc0d 0x558ac66db9ee 0x558ac666ebda 0x558ac66dcc0d 0x558ac66db9ee\n",
            "tcmalloc: large alloc 1366007808 bytes == 0x558be759e000 @  0x7f4476917615 0x558ac666a4cc 0x558ac674a47a 0x558ac6670f0c 0x7f4471b699e4 0x7f4471b71b14 0x7f4471b46a60 0x7f43c9324f55 0x7f43c932088e 0x7f43c9328235 0x7f4471b46fae 0x7f44712bdaa8 0x558ac666e098 0x558ac66e14d9 0x558ac66dbced 0x558ac666ebda 0x558ac66dc915 0x558ac66db9ee 0x558ac666ebda 0x558ac66e0d00 0x558ac666eafa 0x558ac66dc915 0x558ac66db9ee 0x558ac666ebda 0x558ac66dcc0d 0x558ac666eafa 0x558ac66dcc0d 0x558ac66db9ee 0x558ac666ebda 0x558ac66dcc0d 0x558ac66db9ee\n",
            "tcmalloc: large alloc 1707515904 bytes == 0x558b69af8000 @  0x7f4476917615 0x558ac666a4cc 0x558ac674a47a 0x558ac6670f0c 0x7f4471b699e4 0x7f4471b71b14 0x7f4471b46a60 0x7f43c9324f55 0x7f43c932088e 0x7f43c9328235 0x7f4471b46fae 0x7f44712bdaa8 0x558ac666e098 0x558ac66e14d9 0x558ac66dbced 0x558ac666ebda 0x558ac66dc915 0x558ac66db9ee 0x558ac666ebda 0x558ac66e0d00 0x558ac666eafa 0x558ac66dc915 0x558ac66db9ee 0x558ac666ebda 0x558ac66dcc0d 0x558ac666eafa 0x558ac66dcc0d 0x558ac66db9ee 0x558ac666ebda 0x558ac66dcc0d 0x558ac66db9ee\n",
            "Epoch 1:  14% 40/282 [00:38<03:52,  1.04it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  21% 60/282 [00:46<02:51,  1.30it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  28% 80/282 [00:53<02:15,  1.49it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  35% 100/282 [01:00<01:50,  1.64it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  43% 120/282 [01:08<01:31,  1.76it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  50% 140/282 [01:15<01:16,  1.86it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  57% 160/282 [01:22<01:03,  1.93it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  64% 180/282 [01:29<00:50,  2.00it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  71% 200/282 [01:37<00:39,  2.06it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  78% 220/282 [01:44<00:29,  2.11it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  85% 240/282 [01:51<00:19,  2.15it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  92% 260/282 [01:59<00:10,  2.18it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Epoch 1:  99% 280/282 [02:06<00:00,  2.22it/s, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.110, train_acc_epoch=0.324]\n",
            "Validating: 100% 245/245 [01:29<00:00,  2.74it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.1186, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2872, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_1_predictions.csv\n",
            "--------------------\n",
            "Epoch 1: 100% 282/282 [02:08<00:00,  2.20it/s, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.324] \n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(1.0954, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.3547, device='cuda:0')\n",
            "--------------------\n",
            "tcmalloc: large alloc 1707515904 bytes == 0x558b69af8000 @  0x7f4476917615 0x558ac666a4cc 0x558ac674a47a 0x558ac6670f0c 0x7f4471b699e4 0x7f4471b71b14 0x7f4471b46a60 0x7f43c9324f55 0x7f43c932088e 0x7f43c9328235 0x7f4471b46fae 0x7f44712bdaa8 0x558ac666e098 0x558ac66e14d9 0x558ac66dbced 0x558ac666ebda 0x558ac66dc915 0x558ac66db9ee 0x558ac666ebda 0x558ac66e0d00 0x558ac666eafa 0x558ac66dc915 0x558ac66db9ee 0x558ac666ebda 0x558ac66dcc0d 0x558ac666eafa 0x558ac66dcc0d 0x558ac66db9ee 0x558ac666ebda 0x558ac66dcc0d 0x558ac66db9ee\n",
            "Epoch 2:  14% 40/282 [00:38<03:51,  1.04it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  21% 60/282 [00:46<02:50,  1.30it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  28% 80/282 [00:53<02:14,  1.50it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  35% 100/282 [01:00<01:50,  1.65it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  43% 120/282 [01:07<01:31,  1.76it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  50% 140/282 [01:15<01:16,  1.86it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  57% 160/282 [01:22<01:02,  1.94it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  64% 180/282 [01:29<00:50,  2.00it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  71% 200/282 [01:37<00:39,  2.06it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  78% 220/282 [01:44<00:29,  2.11it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  85% 240/282 [01:51<00:19,  2.15it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  92% 260/282 [01:58<00:10,  2.19it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Epoch 2:  99% 280/282 [02:06<00:00,  2.22it/s, loss=1.04, v_num=0, train_loss_step=0.988, train_acc_step=0.500, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "Validating: 100% 245/245 [01:29<00:00,  2.75it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.3286, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.3112, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_2_predictions.csv\n",
            "--------------------\n",
            "Epoch 2: 100% 282/282 [02:08<00:00,  2.20it/s, loss=0.959, v_num=0, train_loss_step=0.931, train_acc_step=0.625, train_loss_epoch=1.100, train_acc_epoch=0.355]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(0.9952, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.5304, device='cuda:0')\n",
            "--------------------\n",
            "Epoch 3:  14% 40/282 [00:38<03:51,  1.04it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  21% 60/282 [00:46<02:50,  1.30it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  28% 80/282 [00:53<02:14,  1.50it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  35% 100/282 [01:00<01:50,  1.65it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  43% 120/282 [01:08<01:31,  1.76it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  50% 140/282 [01:15<01:16,  1.86it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  57% 160/282 [01:22<01:03,  1.94it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  64% 180/282 [01:29<00:50,  2.00it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  71% 200/282 [01:37<00:39,  2.06it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  78% 220/282 [01:44<00:29,  2.10it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  85% 240/282 [01:51<00:19,  2.15it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  92% 260/282 [01:59<00:10,  2.18it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Epoch 3:  99% 280/282 [02:06<00:00,  2.22it/s, loss=0.737, v_num=0, train_loss_step=0.561, train_acc_step=0.875, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "Validating: 100% 245/245 [01:29<00:00,  2.73it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.6126, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2908, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_3_predictions.csv\n",
            "--------------------\n",
            "Epoch 3: 100% 282/282 [02:08<00:00,  2.20it/s, loss=0.666, v_num=0, train_loss_step=0.539, train_acc_step=0.750, train_loss_epoch=0.995, train_acc_epoch=0.530]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(0.6995, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.7128, device='cuda:0')\n",
            "--------------------\n",
            "Epoch 4:  14% 40/282 [00:38<03:52,  1.04it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  21% 60/282 [00:46<02:51,  1.30it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  28% 80/282 [00:53<02:15,  1.49it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  35% 100/282 [01:00<01:50,  1.64it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  43% 120/282 [01:08<01:31,  1.76it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  50% 140/282 [01:15<01:16,  1.86it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  57% 160/282 [01:22<01:03,  1.93it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  64% 180/282 [01:30<00:51,  2.00it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  71% 200/282 [01:37<00:39,  2.06it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  78% 220/282 [01:44<00:29,  2.10it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  85% 240/282 [01:51<00:19,  2.14it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  92% 260/282 [01:59<00:10,  2.18it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Epoch 4:  99% 280/282 [02:06<00:00,  2.21it/s, loss=0.502, v_num=0, train_loss_step=0.273, train_acc_step=1.000, train_loss_epoch=0.700, train_acc_epoch=0.713]\n",
            "Validating: 100% 245/245 [01:29<00:00,  2.73it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.6543, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2949, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_4_predictions.csv\n",
            "--------------------\n",
            "Epoch 4: 100% 282/282 [02:08<00:00,  2.20it/s, loss=0.56, v_num=0, train_loss_step=0.634, train_acc_step=0.750, train_loss_epoch=0.700, train_acc_epoch=0.713] \n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(0.5308, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.8176, device='cuda:0')\n",
            "--------------------\n",
            "Epoch 4: 100% 282/282 [02:17<00:00,  2.06it/s, loss=0.56, v_num=0, train_loss_step=0.634, train_acc_step=0.750, train_loss_epoch=0.700, train_acc_epoch=0.713]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NB39vtBLjY6",
        "outputId": "b4eeb25d-6a66-45cb-d683-fa864c98c420"
      },
      "source": [
        "!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.5.4-py3-none-any.whl (524 kB)\n",
            "\u001b[K     |████████████████████████████████| 524 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
            "\u001b[K     |████████████████████████████████| 329 kB 42.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 32.7 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.62.3)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.7.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.42.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 45.7 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 52.4 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 49.1 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.8)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=9811f29020c48b3bc75efd1e0ed4837dfac5e7f7c11c9259703aa3a988e839b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, future, pytorch-lightning\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2021.11.1 future-0.18.2 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.5.4 torchmetrics-0.6.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEClhBwOLm31",
        "outputId": "161b38f2-4803-4c16-8386-9b1578120f08"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 480 kB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.2.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI5lok53LpNx"
      },
      "source": [
        "import pandas as pd\n",
        "ep0 = pd.read_csv('/content/epoch_0_predictions.csv')\n",
        "ep1 = pd.read_csv('/content/epoch_1_predictions.csv')\n",
        "ep2 = pd.read_csv('/content/epoch_2_predictions.csv')\n",
        "ep3 = pd.read_csv('/content/epoch_3_predictions.csv')\n",
        "ep4 = pd.read_csv('/content/epoch_4_predictions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_TpWzv9Rqtz"
      },
      "source": [
        "import numpy as np\n",
        "difficulty = []\n",
        "confidence = []\n",
        "for i in range(1954):\n",
        "    val1 = ep0.iloc[i][int(ep0.iloc[i]['label'])+2]\n",
        "    val2 = ep1.iloc[i][int(ep1.iloc[i]['label'])+2]\n",
        "    val3 = ep2.iloc[i][int(ep2.iloc[i]['label'])+2]\n",
        "    val4 = ep3.iloc[i][int(ep3.iloc[i]['label'])+2]\n",
        "    val5 = ep4.iloc[i][int(ep4.iloc[i]['label'])+2]\n",
        "    confidence.append((val1+val2+val3+val4+val5)/5)\n",
        "    difficulty.append(np.std([val1,val2,val3,val4,val5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "iCvtf7QQRtD7",
        "outputId": "821d84f0-ae3c-425f-ac1e-c6d820adbd36"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.scatterplot(x= difficulty, y = confidence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2a02acae50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "659Et4urz1T7"
      },
      "source": [
        "import pandas as pd\n",
        "train_df_easy = pd.read_csv('/content/data_easy.csv')\n",
        "train_df_ambi = pd.read_csv('/content/data_ambi.csv')\n",
        "train_df_hard = pd.read_csv('/content/data_hard.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hclf6CnzSc_c"
      },
      "source": [
        "train_easy_100_hard_100 = pd.concat([train_df_easy, train_df_hard])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tikCGG4zvjt"
      },
      "source": [
        "train_easy_100_hard_100.to_csv('train_easy_100_hard_100.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4aMMLxBz3Rl",
        "outputId": "43bc91ce-9ddc-4a56-98e0-7c2b7bb37eac"
      },
      "source": [
        "!python3 /content/mcq_training_lightning_1.py --model_name_or_path bert-base-uncased --hidden_dropout_prob 0.15 --max_input_seq_length 128 --output_dir ./  --predictions_file predictions.csv --TRAIN_FILE /content/train_easy_100_hard_100.csv  --DEV_FILE /content/devnewdata_2.csv --train_batch_size 8 --eval_batch_size 8 --max_train_samples -1 --num_train_epochs 5 --gradient_accumulation_steps 1 --seed 42 --save_top_k -1 --learning_rate 5e-05 --write_dev_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training arguments Namespace(adam_epsilon=1e-08, distributed_backend=None, early_stop_callback=False, fp_16=False, max_grad_norm=1.0, n_gpu=-1, num_workers=8, opt_level='O1', warmup_steps=0, weight_decay=0.0)\n",
            "--------------------\n",
            "Model arguments Namespace(hidden_dropout_prob=0.15, max_input_seq_length=128, model_name_or_path='bert-base-uncased')\n",
            "--------------------\n",
            "Other arguments Namespace(DEV_FILE='/content/devnewdata_2.csv', TRAIN_FILE='/content/train_easy_100_hard_100.csv', do_fast_dev_run=False, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, limit_train_batches=-1, limit_val_batches=-1, max_train_samples=-1, num_train_epochs=5, output_dir='./', predictions_file='predictions.csv', save_last=False, save_top_k=-1, seed=42, train_batch_size=8, write_dev_predictions=True)\n",
            "--------------------\n",
            "Global seed set to 42\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 28.4kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 447kB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 2.00MB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 3.33MB/s]\n",
            "Downloading: 100% 420M/420M [00:11<00:00, 39.6MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                  | Params\n",
            "------------------------------------------------\n",
            "0 | model | BertForMultipleChoice | 109 M \n",
            "------------------------------------------------\n",
            "109 M     Trainable params\n",
            "0         Non-trainable params\n",
            "109 M     Total params\n",
            "437.932   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:623: UserWarning: Checkpoint directory /content exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "Validation sanity check: 0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Validation sanity check:   0% 0/2 [00:00<?, ?it/s]--------------------\n",
            "Validation avg_loss:  tensor(1.1031, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2500, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_0_predictions.csv\n",
            "--------------------\n",
            "Global seed set to 42\n",
            "Epoch 0:  67% 480/720 [10:00<05:00,  1.25s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  69% 500/720 [10:09<04:28,  1.22s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  72% 520/720 [10:18<03:58,  1.19s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  75% 540/720 [10:27<03:29,  1.16s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  78% 560/720 [10:36<03:01,  1.14s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  81% 580/720 [10:46<02:35,  1.11s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  83% 600/720 [10:55<02:11,  1.09s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  86% 620/720 [11:04<01:47,  1.07s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  89% 640/720 [11:13<01:24,  1.05s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  92% 660/720 [11:22<01:02,  1.03s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  94% 680/720 [11:31<00:40,  1.02s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0:  97% 700/720 [11:40<00:20,  1.00s/it, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Epoch 0: 100% 720/720 [11:49<00:00,  1.02it/s, loss=0.742, v_num=0, train_loss_step=0.136, train_acc_step=1.000]\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.23it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.3272, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.4770, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_0_predictions.csv\n",
            "--------------------\n",
            "Epoch 0: 100% 720/720 [11:51<00:00,  1.01it/s, loss=0.707, v_num=0, train_loss_step=1.530, train_acc_step=0.500]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(0.8395, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.6161, device='cuda:0')\n",
            "--------------------\n",
            "tcmalloc: large alloc 1092804608 bytes == 0x55628bffe000 @  0x7fadca41a615 0x5561b3d674cc 0x5561b3e4747a 0x5561b3d6df0c 0x7fadc566c9e4 0x7fadc5674b14 0x7fadc5649a60 0x7fad1ce27f55 0x7fad1ce2388e 0x7fad1ce2b235 0x7fadc5649fae 0x7fadc4dc0aa8 0x5561b3d6b098 0x5561b3dde4d9 0x5561b3dd8ced 0x5561b3d6bbda 0x5561b3dd9915 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dddd00 0x5561b3d6bafa 0x5561b3dd9915 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dd9c0d 0x5561b3d6bafa 0x5561b3dd9c0d 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dd9c0d 0x5561b3dd89ee\n",
            "tcmalloc: large alloc 1366007808 bytes == 0x5562d58e6000 @  0x7fadca41a615 0x5561b3d674cc 0x5561b3e4747a 0x5561b3d6df0c 0x7fadc566c9e4 0x7fadc5674b14 0x7fadc5649a60 0x7fad1ce27f55 0x7fad1ce2388e 0x7fad1ce2b235 0x7fadc5649fae 0x7fadc4dc0aa8 0x5561b3d6b098 0x5561b3dde4d9 0x5561b3dd8ced 0x5561b3d6bbda 0x5561b3dd9915 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dddd00 0x5561b3d6bafa 0x5561b3dd9915 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dd9c0d 0x5561b3d6bafa 0x5561b3dd9c0d 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dd9c0d 0x5561b3dd89ee\n",
            "tcmalloc: large alloc 1707515904 bytes == 0x556257e40000 @  0x7fadca41a615 0x5561b3d674cc 0x5561b3e4747a 0x5561b3d6df0c 0x7fadc566c9e4 0x7fadc5674b14 0x7fadc5649a60 0x7fad1ce27f55 0x7fad1ce2388e 0x7fad1ce2b235 0x7fadc5649fae 0x7fadc4dc0aa8 0x5561b3d6b098 0x5561b3dde4d9 0x5561b3dd8ced 0x5561b3d6bbda 0x5561b3dd9915 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dddd00 0x5561b3d6bafa 0x5561b3dd9915 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dd9c0d 0x5561b3d6bafa 0x5561b3dd9c0d 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dd9c0d 0x5561b3dd89ee\n",
            "Epoch 1:  67% 480/720 [10:01<05:00,  1.25s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  69% 500/720 [10:11<04:28,  1.22s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  72% 520/720 [10:20<03:58,  1.19s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  75% 540/720 [10:29<03:29,  1.17s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  78% 560/720 [10:38<03:02,  1.14s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  81% 580/720 [10:47<02:36,  1.12s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  83% 600/720 [10:56<02:11,  1.09s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  86% 620/720 [11:05<01:47,  1.07s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  89% 640/720 [11:14<01:24,  1.05s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  92% 660/720 [11:23<01:02,  1.04s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  94% 680/720 [11:32<00:40,  1.02s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1:  97% 700/720 [11:41<00:20,  1.00s/it, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Epoch 1: 100% 720/720 [11:50<00:00,  1.01it/s, loss=0.527, v_num=0, train_loss_step=1.010, train_acc_step=0.625, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.21it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.7780, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.5107, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_1_predictions.csv\n",
            "--------------------\n",
            "Epoch 1: 100% 720/720 [11:52<00:00,  1.01it/s, loss=0.383, v_num=0, train_loss_step=0.551, train_acc_step=0.750, train_loss_epoch=0.840, train_acc_epoch=0.616]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(0.4946, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.8197, device='cuda:0')\n",
            "--------------------\n",
            "tcmalloc: large alloc 1707515904 bytes == 0x556257e40000 @  0x7fadca41a615 0x5561b3d674cc 0x5561b3e4747a 0x5561b3d6df0c 0x7fadc566c9e4 0x7fadc5674b14 0x7fadc5649a60 0x7fad1ce27f55 0x7fad1ce2388e 0x7fad1ce2b235 0x7fadc5649fae 0x7fadc4dc0aa8 0x5561b3d6b098 0x5561b3dde4d9 0x5561b3dd8ced 0x5561b3d6bbda 0x5561b3dd9915 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dddd00 0x5561b3d6bafa 0x5561b3dd9915 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dd9c0d 0x5561b3d6bafa 0x5561b3dd9c0d 0x5561b3dd89ee 0x5561b3d6bbda 0x5561b3dd9c0d 0x5561b3dd89ee\n",
            "Epoch 2:  67% 480/720 [10:00<05:00,  1.25s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  69% 500/720 [10:10<04:28,  1.22s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  72% 520/720 [10:19<03:58,  1.19s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  75% 540/720 [10:28<03:29,  1.16s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  78% 560/720 [10:37<03:02,  1.14s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  81% 580/720 [10:46<02:36,  1.12s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  83% 600/720 [10:55<02:11,  1.09s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  86% 620/720 [11:04<01:47,  1.07s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  89% 640/720 [11:13<01:24,  1.05s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  92% 660/720 [11:22<01:02,  1.03s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  94% 680/720 [11:31<00:40,  1.02s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2:  97% 700/720 [11:40<00:20,  1.00s/it, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Epoch 2: 100% 720/720 [11:49<00:00,  1.01it/s, loss=0.199, v_num=0, train_loss_step=0.444, train_acc_step=0.875, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.22it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(2.5006, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.5026, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_2_predictions.csv\n",
            "--------------------\n",
            "Epoch 2: 100% 720/720 [11:52<00:00,  1.01it/s, loss=0.152, v_num=0, train_loss_step=0.0335, train_acc_step=1.000, train_loss_epoch=0.495, train_acc_epoch=0.820]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(0.2555, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.9174, device='cuda:0')\n",
            "--------------------\n",
            "Epoch 3:  67% 480/720 [10:00<05:00,  1.25s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  69% 500/720 [10:10<04:28,  1.22s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  72% 520/720 [10:19<03:58,  1.19s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  75% 540/720 [10:28<03:29,  1.16s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  78% 560/720 [10:37<03:02,  1.14s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  81% 580/720 [10:46<02:36,  1.11s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  83% 600/720 [10:55<02:11,  1.09s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  86% 620/720 [11:04<01:47,  1.07s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  89% 640/720 [11:13<01:24,  1.05s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  92% 660/720 [11:22<01:02,  1.03s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  94% 680/720 [11:31<00:40,  1.02s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3:  97% 700/720 [11:40<00:20,  1.00s/it, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Epoch 3: 100% 720/720 [11:49<00:00,  1.01it/s, loss=0.0841, v_num=0, train_loss_step=0.00585, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.21it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(3.1187, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.5015, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_3_predictions.csv\n",
            "--------------------\n",
            "Epoch 3: 100% 720/720 [11:52<00:00,  1.01it/s, loss=0.0455, v_num=0, train_loss_step=0.00944, train_acc_step=1.000, train_loss_epoch=0.255, train_acc_epoch=0.917]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(0.1055, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.9676, device='cuda:0')\n",
            "--------------------\n",
            "Epoch 4:  67% 480/720 [10:01<05:00,  1.25s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  69% 500/720 [10:10<04:28,  1.22s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  72% 520/720 [10:19<03:58,  1.19s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  75% 540/720 [10:28<03:29,  1.16s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  78% 560/720 [10:37<03:02,  1.14s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  81% 580/720 [10:46<02:36,  1.12s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  83% 600/720 [10:55<02:11,  1.09s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  86% 620/720 [11:05<01:47,  1.07s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  89% 640/720 [11:14<01:24,  1.05s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  92% 660/720 [11:23<01:02,  1.04s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  94% 680/720 [11:32<00:40,  1.02s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4:  97% 700/720 [11:41<00:20,  1.00s/it, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Epoch 4: 100% 720/720 [11:50<00:00,  1.01it/s, loss=0.0267, v_num=0, train_loss_step=0.0371, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.21it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(3.5226, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.5041, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_4_predictions.csv\n",
            "--------------------\n",
            "Epoch 4: 100% 720/720 [11:52<00:00,  1.01it/s, loss=0.052, v_num=0, train_loss_step=0.00373, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(0.0345, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.9858, device='cuda:0')\n",
            "--------------------\n",
            "Epoch 4: 100% 720/720 [12:01<00:00,  1.00s/it, loss=0.052, v_num=0, train_loss_step=0.00373, train_acc_step=1.000, train_loss_epoch=0.105, train_acc_epoch=0.968]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeYHYZ0x0nDj"
      },
      "source": [
        "train_ambi_75_hard_100 = pd.concat([train_df_ambi.iloc[:900], train_df_hard])\n",
        "train_ambi_75_hard_100.to_csv('train_ambi_75_hard_100.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfd0G2wKC2yo",
        "outputId": "810ed61e-6a2c-4465-f152-3425bffbb6d1"
      },
      "source": [
        "!python3 /content/mcq_training_lightning_1.py --model_name_or_path bert-base-uncased --hidden_dropout_prob 0.15 --max_input_seq_length 128 --output_dir ./  --predictions_file predictions.csv --TRAIN_FILE /content/train_ambi_75_hard_100.csv  --DEV_FILE /content/devnewdata_2.csv --train_batch_size 8 --eval_batch_size 8 --max_train_samples -1 --num_train_epochs 5 --gradient_accumulation_steps 1 --seed 42 --save_top_k -1 --learning_rate 5e-05 --write_dev_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training arguments Namespace(adam_epsilon=1e-08, distributed_backend=None, early_stop_callback=False, fp_16=False, max_grad_norm=1.0, n_gpu=-1, num_workers=8, opt_level='O1', warmup_steps=0, weight_decay=0.0)\n",
            "--------------------\n",
            "Model arguments Namespace(hidden_dropout_prob=0.15, max_input_seq_length=128, model_name_or_path='bert-base-uncased')\n",
            "--------------------\n",
            "Other arguments Namespace(DEV_FILE='/content/devnewdata_2.csv', TRAIN_FILE='/content/train_ambi_75_hard_100.csv', do_fast_dev_run=False, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, limit_train_batches=-1, limit_val_batches=-1, max_train_samples=-1, num_train_epochs=5, output_dir='./', predictions_file='predictions.csv', save_last=False, save_top_k=-1, seed=42, train_batch_size=8, write_dev_predictions=True)\n",
            "--------------------\n",
            "Global seed set to 42\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                  | Params\n",
            "------------------------------------------------\n",
            "0 | model | BertForMultipleChoice | 109 M \n",
            "------------------------------------------------\n",
            "109 M     Trainable params\n",
            "0         Non-trainable params\n",
            "109 M     Total params\n",
            "437.932   Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:623: UserWarning: Checkpoint directory /content exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "Validation sanity check: 0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Validation sanity check:   0% 0/2 [00:00<?, ?it/s]--------------------\n",
            "Validation avg_loss:  tensor(1.1031, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2500, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_0_predictions.csv\n",
            "--------------------\n",
            "Global seed set to 42\n",
            "Epoch 0:  34% 120/348 [02:10<04:08,  1.09s/it, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  40% 140/348 [02:20<03:28,  1.00s/it, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  46% 160/348 [02:29<02:55,  1.07it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  52% 180/348 [02:38<02:27,  1.14it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  57% 200/348 [02:47<02:03,  1.20it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  63% 220/348 [02:56<01:42,  1.25it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  69% 240/348 [03:05<01:23,  1.30it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  75% 260/348 [03:14<01:05,  1.34it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  80% 280/348 [03:23<00:49,  1.38it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  86% 300/348 [03:32<00:33,  1.41it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  92% 320/348 [03:41<00:19,  1.45it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Epoch 0:  98% 340/348 [03:50<00:05,  1.48it/s, loss=1.1, v_num=1, train_loss_step=1.130, train_acc_step=0.375]\n",
            "Validating:  98% 240/245 [01:48<00:02,  2.22it/s]\u001b[A\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.23it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.0988, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.3337, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_0_predictions.csv\n",
            "--------------------\n",
            "Epoch 0: 100% 348/348 [04:01<00:00,  1.44it/s, loss=1.11, v_num=1, train_loss_step=1.080, train_acc_step=0.250]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(1.1153, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.3095, device='cuda:0')\n",
            "--------------------\n",
            "tcmalloc: large alloc 1092804608 bytes == 0x55651efaa000 @  0x7f5227d35615 0x55640282a4cc 0x55640290a47a 0x556402830f0c 0x7f5222f879e4 0x7f5222f8fb14 0x7f5222f64a60 0x7f517a742f55 0x7f517a73e88e 0x7f517a746235 0x7f5222f64fae 0x7f52226dbaa8 0x55640282e098 0x5564028a14d9 0x55640289bced 0x55640282ebda 0x55640289c915 0x55640289b9ee 0x55640282ebda 0x5564028a0d00 0x55640282eafa 0x55640289c915 0x55640289b9ee 0x55640282ebda 0x55640289cc0d 0x55640282eafa 0x55640289cc0d 0x55640289b9ee 0x55640282ebda 0x55640289cc0d 0x55640289b9ee\n",
            "tcmalloc: large alloc 1366007808 bytes == 0x5564a600e000 @  0x7f5227d35615 0x55640282a4cc 0x55640290a47a 0x556402830f0c 0x7f5222f879e4 0x7f5222f8fb14 0x7f5222f64a60 0x7f517a742f55 0x7f517a73e88e 0x7f517a746235 0x7f5222f64fae 0x7f52226dbaa8 0x55640282e098 0x5564028a14d9 0x55640289bced 0x55640282ebda 0x55640289c915 0x55640289b9ee 0x55640282ebda 0x5564028a0d00 0x55640282eafa 0x55640289c915 0x55640289b9ee 0x55640282ebda 0x55640289cc0d 0x55640282eafa 0x55640289cc0d 0x55640289b9ee 0x55640282ebda 0x55640289cc0d 0x55640289b9ee\n",
            "tcmalloc: large alloc 1707515904 bytes == 0x55651efaa000 @  0x7f5227d35615 0x55640282a4cc 0x55640290a47a 0x556402830f0c 0x7f5222f879e4 0x7f5222f8fb14 0x7f5222f64a60 0x7f517a742f55 0x7f517a73e88e 0x7f517a746235 0x7f5222f64fae 0x7f52226dbaa8 0x55640282e098 0x5564028a14d9 0x55640289bced 0x55640282ebda 0x55640289c915 0x55640289b9ee 0x55640282ebda 0x5564028a0d00 0x55640282eafa 0x55640289c915 0x55640289b9ee 0x55640282ebda 0x55640289cc0d 0x55640282eafa 0x55640289cc0d 0x55640289b9ee 0x55640282ebda 0x55640289cc0d 0x55640289b9ee\n",
            "Epoch 1:  34% 120/348 [02:11<04:09,  1.09s/it, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  40% 140/348 [02:21<03:29,  1.01s/it, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  46% 160/348 [02:30<02:56,  1.07it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  52% 180/348 [02:39<02:28,  1.13it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  57% 200/348 [02:48<02:04,  1.19it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  63% 220/348 [02:57<01:43,  1.24it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  69% 240/348 [03:06<01:23,  1.29it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  75% 260/348 [03:15<01:06,  1.33it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  80% 280/348 [03:24<00:49,  1.37it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  86% 300/348 [03:33<00:34,  1.41it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  92% 320/348 [03:42<00:19,  1.44it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Epoch 1:  98% 340/348 [03:51<00:05,  1.47it/s, loss=1.11, v_num=1, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.120, train_acc_epoch=0.309]\n",
            "Validating:  98% 240/245 [01:49<00:02,  2.21it/s]\u001b[A\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.21it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.0989, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.3071, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_1_predictions.csv\n",
            "--------------------\n",
            "Epoch 1: 100% 348/348 [04:02<00:00,  1.43it/s, loss=1.1, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.120, train_acc_epoch=0.309] \n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(1.1123, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.3350, device='cuda:0')\n",
            "--------------------\n",
            "tcmalloc: large alloc 1707515904 bytes == 0x5564a600e000 @  0x7f5227d35615 0x55640282a4cc 0x55640290a47a 0x556402830f0c 0x7f5222f879e4 0x7f5222f8fb14 0x7f5222f64a60 0x7f517a742f55 0x7f517a73e88e 0x7f517a746235 0x7f5222f64fae 0x7f52226dbaa8 0x55640282e098 0x5564028a14d9 0x55640289bced 0x55640282ebda 0x55640289c915 0x55640289b9ee 0x55640282ebda 0x5564028a0d00 0x55640282eafa 0x55640289c915 0x55640289b9ee 0x55640282ebda 0x55640289cc0d 0x55640282eafa 0x55640289cc0d 0x55640289b9ee 0x55640282ebda 0x55640289cc0d 0x55640289b9ee\n",
            "Epoch 2:  34% 120/348 [02:11<04:09,  1.09s/it, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  40% 140/348 [02:21<03:29,  1.01s/it, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  46% 160/348 [02:30<02:56,  1.07it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  52% 180/348 [02:39<02:28,  1.13it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  57% 200/348 [02:48<02:04,  1.19it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  63% 220/348 [02:57<01:43,  1.24it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  69% 240/348 [03:06<01:23,  1.29it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  75% 260/348 [03:15<01:06,  1.33it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  80% 280/348 [03:24<00:49,  1.37it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  86% 300/348 [03:33<00:34,  1.41it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  92% 320/348 [03:42<00:19,  1.44it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Epoch 2:  98% 340/348 [03:51<00:05,  1.47it/s, loss=1.11, v_num=1, train_loss_step=1.120, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "Validating:  98% 240/245 [01:49<00:02,  2.21it/s]\u001b[A\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.21it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.0988, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2781, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_2_predictions.csv\n",
            "--------------------\n",
            "Epoch 2: 100% 348/348 [04:02<00:00,  1.43it/s, loss=1.11, v_num=1, train_loss_step=1.080, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.335]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(1.1020, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.3629, device='cuda:0')\n",
            "--------------------\n",
            "Epoch 3:  34% 120/348 [02:11<04:09,  1.09s/it, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  40% 140/348 [02:20<03:29,  1.01s/it, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  46% 160/348 [02:29<02:56,  1.07it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  52% 180/348 [02:39<02:28,  1.13it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  57% 200/348 [02:48<02:04,  1.19it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  63% 220/348 [02:57<01:43,  1.24it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  69% 240/348 [03:06<01:23,  1.29it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  75% 260/348 [03:15<01:06,  1.33it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  80% 280/348 [03:24<00:49,  1.37it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  86% 300/348 [03:33<00:34,  1.41it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  92% 320/348 [03:42<00:19,  1.44it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Epoch 3:  98% 340/348 [03:51<00:05,  1.47it/s, loss=1.09, v_num=1, train_loss_step=1.120, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "Validating:  98% 240/245 [01:49<00:02,  2.21it/s]\u001b[A\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.21it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.0990, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2827, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_3_predictions.csv\n",
            "--------------------\n",
            "Epoch 3: 100% 348/348 [04:02<00:00,  1.43it/s, loss=1.09, v_num=1, train_loss_step=1.090, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.363]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(1.1056, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.3362, device='cuda:0')\n",
            "--------------------\n",
            "Epoch 4:  34% 120/348 [02:11<04:09,  1.09s/it, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/245 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  40% 140/348 [02:21<03:29,  1.01s/it, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  46% 160/348 [02:30<02:56,  1.07it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  52% 180/348 [02:39<02:28,  1.13it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  57% 200/348 [02:48<02:04,  1.19it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  63% 220/348 [02:57<01:43,  1.24it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  69% 240/348 [03:06<01:23,  1.29it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  75% 260/348 [03:15<01:06,  1.33it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  80% 280/348 [03:24<00:49,  1.37it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  86% 300/348 [03:33<00:34,  1.41it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  92% 320/348 [03:42<00:19,  1.44it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4:  98% 340/348 [03:51<00:05,  1.47it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Epoch 4: 100% 348/348 [04:02<00:00,  1.44it/s, loss=1.11, v_num=1, train_loss_step=1.170, train_acc_step=0.125, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "Validating: 100% 245/245 [01:51<00:00,  2.21it/s]\u001b[A--------------------\n",
            "Validation avg_loss:  tensor(1.0991, device='cuda:0')\n",
            "Validation avg_acc:  tensor(0.2811, device='cuda:0')\n",
            "Writing predictions for /content/devnewdata_2.csv to ./epoch_4_predictions.csv\n",
            "--------------------\n",
            "Epoch 4: 100% 348/348 [04:02<00:00,  1.43it/s, loss=1.11, v_num=1, train_loss_step=1.150, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.336]\n",
            "                                                 \u001b[A--------------------\n",
            "Train avg_loss:  tensor(1.1089, device='cuda:0')\n",
            "Train avg_acc:  tensor(0.3289, device='cuda:0')\n",
            "--------------------\n",
            "Epoch 4: 100% 348/348 [04:11<00:00,  1.38it/s, loss=1.11, v_num=1, train_loss_step=1.150, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.336]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92EHbDI_DBJd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}