Training arguments Namespace(adam_epsilon=1e-08, distributed_backend=None, early_stop_callback=False, fp_16=False, max_grad_norm=1.0, n_gpu=-1, num_workers=8, opt_level='O1', warmup_steps=0, weight_decay=0.0)
--------------------
Model arguments Namespace(hidden_dropout_prob=0.15, max_input_seq_length=128, model_name_or_path='bert-base-uncased')
--------------------
Other arguments Namespace(DEV_FILE='contentdevnewdata_2.csv', TRAIN_FILE='contentdata_ambi.csv', do_fast_dev_run=False, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, limit_train_batches=-1, limit_val_batches=-1, max_train_samples=-1, num_train_epochs=5, output_dir='.', predictions_file='predictions.csv', save_last=False, save_top_k=-1, seed=42, train_batch_size=8, write_dev_predictions=True)
--------------------
Global seed set to 42
Downloading 100% 28.028.0 [00000000, 24.2kBs]
Downloading 100% 570570 [00000000, 447kBs]
Downloading 100% 226k226k [00000000, 712kBs]
Downloading 100% 455k455k [00000000, 1.15MBs]
Downloading 100% 420M420M [00100000, 40.9MBs]
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
GPU available True, used True
TPU available False, using 0 TPU cores
IPU available False, using 0 IPUs
LOCAL_RANK 0 - CUDA_VISIBLE_DEVICES [0]

   Name   Type                   Params
------------------------------------------------
0  model  BertForMultipleChoice  109 M 
------------------------------------------------
109 M     Trainable params
0         Non-trainable params
109 M     Total params
437.932   Total estimated model params size (MB)
usrlocallibpython3.7dist-packagespytorch_lightningcallbacksmodel_checkpoint.py623 UserWarning Checkpoint directory content exists and is not empty.
  rank_zero_warn(fCheckpoint directory {dirpath} exists and is not empty.)
Validation sanity check 0it [0000, its]usrlocallibpython3.7dist-packagestorchutilsdatadataloader.py481 UserWarning This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slownessfreeze if necessary.
  cpuset_checked))
Validation sanity check   0% 02 [0000, its]--------------------
Validation avg_loss  tensor(1.1031, device='cuda0')
Validation avg_acc  tensor(0.2500, device='cuda0')
Writing predictions for contentdevnewdata_2.csv to .epoch_0_predictions.csv
--------------------
Global seed set to 42
Epoch 0  41% 160395 [02330344,  1.04its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Validating 0it [0000, its]
Validating   0% 0245 [0000, its]
Epoch 0  46% 180395 [02410312,  1.12its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  51% 200395 [02480244,  1.19its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  56% 220395 [02550219,  1.25its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  61% 240395 [03030158,  1.31its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  66% 260395 [03100138,  1.36its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  71% 280395 [03180121,  1.41its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  76% 300395 [03250105,  1.46its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  81% 320395 [03320049,  1.50its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  86% 340395 [03400035,  1.54its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  91% 360395 [03470022,  1.58its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Epoch 0  96% 380395 [03550009,  1.62its, loss=1.1, v_num=0, train_loss_step=1.110, train_acc_step=0.250]
Validating  98% 240245 [01290001,  2.70its]
Validating 100% 245245 [01310000,  2.71its]--------------------
Validation avg_loss  tensor(1.0995, device='cuda0')
Validation avg_acc  tensor(0.3168, device='cuda0')
Writing predictions for contentdevnewdata_2.csv to .epoch_0_predictions.csv
--------------------
Epoch 0 100% 395395 [04040000,  1.62its, loss=1.12, v_num=0, train_loss_step=1.120, train_acc_step=0.250]
                                                 --------------------
Train avg_loss  tensor(1.1126, device='cuda0')
Train avg_acc  tensor(0.3258, device='cuda0')
--------------------
tcmalloc large alloc 1092804608 bytes == 0x55e4e1c44000 @  0x7f3a3a7fd615 0x55e40ab9c4cc 0x55e40ac7c47a 0x55e40aba2f0c 0x7f3a35a4f9e4 0x7f3a35a57b14 0x7f3a35a2ca60 0x7f398d20af55 0x7f398d20688e 0x7f398d20e235 0x7f3a35a2cfae 0x7f3a351a3aa8 0x55e40aba0098 0x55e40ac134d9 0x55e40ac0dced 0x55e40aba0bda 0x55e40ac0e915 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac12d00 0x55e40aba0afa 0x55e40ac0e915 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac0ec0d 0x55e40aba0afa 0x55e40ac0ec0d 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac0ec0d 0x55e40ac0d9ee
Epoch 0 100% 395395 [04070000,  1.60its, loss=1.12, v_num=0, train_loss_step=1.120, train_acc_step=0.250]tcmalloc large alloc 1366007808 bytes == 0x55e52b52c000 @  0x7f3a3a7fd615 0x55e40ab9c4cc 0x55e40ac7c47a 0x55e40aba2f0c 0x7f3a35a4f9e4 0x7f3a35a57b14 0x7f3a35a2ca60 0x7f398d20af55 0x7f398d20688e 0x7f398d20e235 0x7f3a35a2cfae 0x7f3a351a3aa8 0x55e40aba0098 0x55e40ac134d9 0x55e40ac0dced 0x55e40aba0bda 0x55e40ac0e915 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac12d00 0x55e40aba0afa 0x55e40ac0e915 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac0ec0d 0x55e40aba0afa 0x55e40ac0ec0d 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac0ec0d 0x55e40ac0d9ee
tcmalloc large alloc 1707515904 bytes == 0x55e4ada86000 @  0x7f3a3a7fd615 0x55e40ab9c4cc 0x55e40ac7c47a 0x55e40aba2f0c 0x7f3a35a4f9e4 0x7f3a35a57b14 0x7f3a35a2ca60 0x7f398d20af55 0x7f398d20688e 0x7f398d20e235 0x7f3a35a2cfae 0x7f3a351a3aa8 0x55e40aba0098 0x55e40ac134d9 0x55e40ac0dced 0x55e40aba0bda 0x55e40ac0e915 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac12d00 0x55e40aba0afa 0x55e40ac0e915 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac0ec0d 0x55e40aba0afa 0x55e40ac0ec0d 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac0ec0d 0x55e40ac0d9ee
Epoch 1  41% 160395 [02330345,  1.04its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Validating 0it [0000, its]
Validating   0% 0245 [0000, its]
Epoch 1  46% 180395 [02410313,  1.11its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  51% 200395 [02490244,  1.18its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  56% 220395 [02560220,  1.25its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  61% 240395 [03030158,  1.31its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  66% 260395 [03110139,  1.36its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  71% 280395 [03180121,  1.41its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  76% 300395 [03260105,  1.46its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  81% 320395 [03330050,  1.50its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  86% 340395 [03400035,  1.54its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  91% 360395 [03480022,  1.58its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Epoch 1  96% 380395 [03550009,  1.61its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.625, train_loss_epoch=1.110, train_acc_epoch=0.326]
Validating  98% 240245 [01290001,  2.70its]
Validating 100% 245245 [01310000,  2.69its]--------------------
Validation avg_loss  tensor(1.0986, device='cuda0')
Validation avg_acc  tensor(0.3327, device='cuda0')
Writing predictions for contentdevnewdata_2.csv to .epoch_1_predictions.csv
--------------------
Epoch 1 100% 395395 [04050000,  1.61its, loss=1.09, v_num=0, train_loss_step=1.060, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.326]
                                                 --------------------
Train avg_loss  tensor(1.1111, device='cuda0')
Train avg_acc  tensor(0.3283, device='cuda0')
--------------------
tcmalloc large alloc 1707515904 bytes == 0x55e4ada86000 @  0x7f3a3a7fd615 0x55e40ab9c4cc 0x55e40ac7c47a 0x55e40aba2f0c 0x7f3a35a4f9e4 0x7f3a35a57b14 0x7f3a35a2ca60 0x7f398d20af55 0x7f398d20688e 0x7f398d20e235 0x7f3a35a2cfae 0x7f3a351a3aa8 0x55e40aba0098 0x55e40ac134d9 0x55e40ac0dced 0x55e40aba0bda 0x55e40ac0e915 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac12d00 0x55e40aba0afa 0x55e40ac0e915 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac0ec0d 0x55e40aba0afa 0x55e40ac0ec0d 0x55e40ac0d9ee 0x55e40aba0bda 0x55e40ac0ec0d 0x55e40ac0d9ee
Epoch 2  41% 160395 [02330345,  1.04its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Validating 0it [0000, its]
Validating   0% 0245 [0000, its]
Epoch 2  46% 180395 [02410312,  1.12its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  51% 200395 [02480244,  1.19its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  56% 220395 [02560220,  1.25its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  61% 240395 [03030158,  1.31its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  66% 260395 [03100139,  1.36its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  71% 280395 [03180121,  1.41its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  76% 300395 [03250105,  1.46its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  81% 320395 [03330049,  1.50its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  86% 340395 [03400035,  1.54its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  91% 360395 [03470022,  1.58its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Epoch 2  96% 380395 [03550009,  1.61its, loss=1.1, v_num=0, train_loss_step=1.090, train_acc_step=0.500, train_loss_epoch=1.110, train_acc_epoch=0.328]
Validating  98% 240245 [01290001,  2.70its]
Validating 100% 245245 [01310000,  2.70its]--------------------
Validation avg_loss  tensor(1.0986, device='cuda0')
Validation avg_acc  tensor(0.3551, device='cuda0')
Writing predictions for contentdevnewdata_2.csv to .epoch_2_predictions.csv
--------------------
Epoch 2 100% 395395 [04040000,  1.61its, loss=1.1, v_num=0, train_loss_step=1.160, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.328]
                                                 --------------------
Train avg_loss  tensor(1.1102, device='cuda0')
Train avg_acc  tensor(0.3392, device='cuda0')
--------------------
Epoch 3  41% 160395 [02330345,  1.04its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Validating 0it [0000, its]
Validating   0% 0245 [0000, its]
Epoch 3  46% 180395 [02410313,  1.11its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  51% 200395 [02490244,  1.18its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  56% 220395 [02560220,  1.25its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  61% 240395 [03030158,  1.30its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  66% 260395 [03110139,  1.36its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  71% 280395 [03180121,  1.41its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  76% 300395 [03260105,  1.46its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  81% 320395 [03330050,  1.50its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  86% 340395 [03400035,  1.54its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  91% 360395 [03480022,  1.58its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Epoch 3  96% 380395 [03550009,  1.61its, loss=1.1, v_num=0, train_loss_step=1.100, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
Validating  98% 240245 [01290001,  2.70its]
Validating 100% 245245 [01310000,  2.69its]--------------------
Validation avg_loss  tensor(1.0986, device='cuda0')
Validation avg_acc  tensor(0.3480, device='cuda0')
Writing predictions for contentdevnewdata_2.csv to .epoch_3_predictions.csv
--------------------
Epoch 3 100% 395395 [04050000,  1.61its, loss=1.11, v_num=0, train_loss_step=1.110, train_acc_step=0.250, train_loss_epoch=1.110, train_acc_epoch=0.339]
                                                 --------------------
Train avg_loss  tensor(1.1025, device='cuda0')
Train avg_acc  tensor(0.3475, device='cuda0')
--------------------
Epoch 4  41% 160395 [02340346,  1.04its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Validating 0it [0000, its]
Validating   0% 0245 [0000, its]
Epoch 4  46% 180395 [02420313,  1.11its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  51% 200395 [02490245,  1.18its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  56% 220395 [02560220,  1.24its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  61% 240395 [03040159,  1.30its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  66% 260395 [03110139,  1.36its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  71% 280395 [03190121,  1.41its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  76% 300395 [03260105,  1.45its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  81% 320395 [03330050,  1.50its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  86% 340395 [03410035,  1.54its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  91% 360395 [03480022,  1.57its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Epoch 4  96% 380395 [03560009,  1.61its, loss=1.09, v_num=0, train_loss_step=1.100, train_acc_step=0.375, train_loss_epoch=1.100, train_acc_epoch=0.347]
Validating  98% 240245 [01290001,  2.70its]
Validating 100% 245245 [01310000,  2.69its]--------------------
Validation avg_loss  tensor(1.0986, device='cuda0')
Validation avg_acc  tensor(0.3388, device='cuda0')
Writing predictions for contentdevnewdata_2.csv to .epoch_4_predictions.csv
--------------------
Epoch 4 100% 395395 [04050000,  1.61its, loss=1.1, v_num=0, train_loss_step=1.130, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.347] 
                                                 --------------------
Train avg_loss  tensor(1.1046, device='cuda0')
Train avg_acc  tensor(0.3375, device='cuda0')
--------------------
Epoch 4 100% 395395 [04130000,  1.56its, loss=1.1, v_num=0, train_loss_step=1.130, train_acc_step=0.250, train_loss_epoch=1.100, train_acc_epoch=0.347]
